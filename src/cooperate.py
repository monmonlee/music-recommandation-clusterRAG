

# ============================================================================
# å¥—ä»¶å°å…¥
# ============================================================================
import os
import json
import time
import uuid
import shutil
import datetime
from tqdm import tqdm
from dotenv import load_dotenv, find_dotenv
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import chromadb
import anthropic
import gradio as gr
from router import QueryRouter, QueryType
import joblib
import pandas as pd


# ============================================================================
# å…¨åŸŸè¨­å®šï¼ˆå·²æ”¹ç‚ºæœ¬æ©Ÿç‰ˆæœ¬â€¼ï¼‰
# ============================================================================

# å°‡é€™å€‹æ”¹æˆä½ è‡ªå·±çš„æœ¬æ©Ÿè³‡æ–™å¤¾ä½ç½®ï¼ˆä½ æ”¾ dataset.csvã€chroma_db çš„åœ°æ–¹ï¼‰
# å»ºè­°ä½ æŠŠé€™å€‹è³‡æ–™å¤¾å‘½åç‚º `spotify_data/`
DRIVE_ROOT = "/Users/mangtinglee/Desktop/UT/data mining/æœŸæœ«"

DATA_PATH = os.path.join(DRIVE_ROOT, "dataset.csv")
DB_PATH = os.path.join(DRIVE_ROOT, "chroma_db")
LOG_PATH = os.path.join(DRIVE_ROOT, "query_log.txt")


# API è¨­å®š
_ = load_dotenv(find_dotenv())
ANTHROPIC_API_KEY = os.environ['ANTHROPIC_API_KEY']   # â† æ”¹æˆä½ è‡ªå·±çš„ key
CLAUDE_MODEL = "claude-3-5-haiku-20241022"  # å»ºè­°æ”¹ç”¨æœ€æ–°æ¨¡å‹

# æ¨è–¦æ•¸é‡è¨­å®š
CANDIDATE_SIZE = 50
FINAL_RECOMMENDATION = 10

# ============================================================================
# åˆå§‹åŒ–å…¨åŸŸç‰©ä»¶
# ============================================================================
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
claude_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

chroma_client = None
collections = {}
chat_sessions = {}


# ============================================================================
# è³‡æ–™è™•ç†å‡½æ•¸
# ============================================================================
def normalize_numeric(row):
    """
    å°‡æ•¸å€¼æ¬„ä½æ¨™æº–åŒ–åˆ° 0-1 ç¯„åœï¼Œçµ„æˆ 10 ç¶­å‘é‡
    
    Args:
        row: DataFrame çš„ä¸€è¡Œè³‡æ–™
        
    Returns:
        list: æ¨™æº–åŒ–å¾Œçš„ 10 ç¶­æ•¸å€¼å‘é‡
    """
    return [
        row['danceability'],
        row['energy'],
        row['valence'],
        row['tempo'] / 200,  # tempo ç´„ 0-200
        row['acousticness'],
        row['speechiness'],
        row['instrumentalness'],
        row['liveness'],
        (row['loudness'] + 60) / 60,  # loudness ç´„ -60 åˆ° 0
        row['popularity'] / 100
    ]


def load_dataset(filepath):
    """
    è®€å– Spotify è³‡æ–™é›†
    
    Args:
        filepath: CSV æª”æ¡ˆè·¯å¾‘
        
    Returns:
        pd.DataFrame: è³‡æ–™é›†
    """
    df = pd.read_csv(filepath)
    print(f"âœ“ è³‡æ–™ç­†æ•¸: {len(df)}")
    print(f"âœ“ æ¬„ä½: {df.columns.tolist()}")
    return df

# ============================================================================
# ChromaDB æ“ä½œå‡½æ•¸ï¼ˆæœ¬æ©Ÿç‰ˆæœ¬ï¼‰
# ============================================================================
def initialize_chromadb(db_path):
    """
    åˆå§‹åŒ– ChromaDB å®¢æˆ¶ç«¯ä¸¦è¼‰å…¥ collections
    """
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å‘é‡è³‡æ–™åº«è³‡æ–™å¤¾: {db_path}")

    client = chromadb.PersistentClient(path=db_path)

    collections = {
        "artist": client.get_collection("artist"),
        "track": client.get_collection("track"),
        "genre": client.get_collection("genre"),
        "combined": client.get_collection("combined"),
        "numeric": client.get_collection("numeric")
    }

    print("\nâœ“ ChromaDB è¼‰å…¥æˆåŠŸï¼ˆæœ¬æ©Ÿæ¨¡å¼ï¼‰")
    for name, col in collections.items():
        print(f"  - {name}: {col.count()} ç­†è³‡æ–™")

    return client, collections



def build_vector_database(df, collections, batch_size=500):
    """
    å»ºç«‹å‘é‡è³‡æ–™åº«ï¼ˆé¦–æ¬¡å»ºç«‹æ™‚ä½¿ç”¨ï¼‰
    
    Args:
        df: è³‡æ–™é›†
        collections: ChromaDB collections
        batch_size: æ‰¹æ¬¡å¤§å°
    """
    print(f"é–‹å§‹å»ºç«‹å‘é‡è³‡æ–™åº«ï¼ˆå®Œæ•´ {len(df)} ç­†ï¼‰...")
    print("é ä¼°æ™‚é–“ï¼šç´„ 2 å°æ™‚\n")
    
    total_batches = (len(df) + batch_size - 1) // batch_size
    
    for i in tqdm(range(0, len(df), batch_size), total=total_batches, desc="å»ºç«‹ä¸­"):
        batch = df.iloc[i:i+batch_size]
        
        # æº–å‚™ IDs
        ids = [str(idx) for idx in batch.index]
        
        # æº–å‚™æ–‡å­—è³‡æ–™
        artists = batch['artists'].fillna('').tolist()
        tracks = batch['track_name'].fillna('').tolist()
        genres = batch['track_genre'].fillna('').tolist()
        combined = [f"ARTIST: {a} TRACK: {t} GENRE: {g}" 
                   for a, t, g in zip(artists, tracks, genres)]
        
        # ç”Ÿæˆ embeddings
        artist_emb = embedding_model.encode(artists).tolist()
        track_emb = embedding_model.encode(tracks).tolist()
        genre_emb = embedding_model.encode(genres).tolist()
        combined_emb = embedding_model.encode(combined).tolist()
        numeric_emb = [normalize_numeric(row) for _, row in batch.iterrows()]
        
        # æº–å‚™ metadata
        metadatas = batch[[
            'track_id', 'artists', 'track_name', 'album_name', 'track_genre',
            'popularity', 'danceability', 'energy', 'valence', 'tempo',
            'acousticness', 'speechiness', 'instrumentalness', 'liveness', 'loudness'
        ]].to_dict('records')
        
        # å¯«å…¥å„ collection
        collections['artist'].add(ids=ids, embeddings=artist_emb, metadatas=metadatas)
        collections['track'].add(ids=ids, embeddings=track_emb, metadatas=metadatas)
        collections['genre'].add(ids=ids, embeddings=genre_emb, metadatas=metadatas)
        collections['combined'].add(ids=ids, embeddings=combined_emb, metadatas=metadatas)
        collections['numeric'].add(ids=ids, embeddings=numeric_emb, metadatas=metadatas)
    
    print(f"\nâœ“ å»ºç«‹å®Œæˆï¼Œæ¯å€‹ Collection å„ {collections['combined'].count()} ç­†")


# ============================================================================
# æª¢ç´¢å‡½æ•¸
# ============================================================================
def search_by_artist(query, n=50):
    """ç”¨è—äººåç¨±æœå°‹"""
    emb = embedding_model.encode(query).tolist()
    return collections['artist'].query(query_embeddings=[emb], n_results=n)


def search_by_track(query, n=50):
    """ç”¨æ­Œæ›²åç¨±æœå°‹"""
    emb = embedding_model.encode(query).tolist()
    return collections['track'].query(query_embeddings=[emb], n_results=n)


def search_by_genre(query, n=50):
    """
    ç”¨é¡å‹æœå°‹ - å„ªå…ˆç²¾ç¢ºåŒ¹é…ï¼Œå¤±æ•—å‰‡ç”¨å‘é‡æª¢ç´¢
    
    Args:
        query: é¡å‹æŸ¥è©¢
        n: è¿”å›æ•¸é‡
        
    Returns:
        æª¢ç´¢çµæœ
    """
    # å˜—è©¦ç²¾ç¢ºåŒ¹é…
    try:
        results = collections['genre'].get(
            where={"track_genre": query.lower()},
            limit=n
        )
        if results['ids']:
            return {'metadatas': [results['metadatas']], 'ids': [results['ids']]}
    except:
        pass
    
    # å›é€€åˆ°å‘é‡æª¢ç´¢
    emb = embedding_model.encode(query).tolist()
    return collections['genre'].query(query_embeddings=[emb], n_results=n)


def search_combined(query, n=50):
    """ç”¨çµ„åˆæ–‡å­—æœå°‹"""
    emb = embedding_model.encode(query).tolist()
    return collections['combined'].query(query_embeddings=[emb], n_results=n)


def search_by_numeric(danceability=0.5, energy=0.5, valence=0.5, tempo=120,
                      acousticness=0.5, speechiness=0.5, instrumentalness=0.5,
                      liveness=0.5, loudness=-10, popularity=50, n=50):
    """ç”¨æ•¸å€¼ç‰¹å¾µå‘é‡æœå°‹"""
    numeric_vector = [
        danceability, energy, valence, tempo/200,
        acousticness, speechiness, instrumentalness, liveness,
        (loudness+60)/60, popularity/100
    ]
    return collections['numeric'].query(query_embeddings=[numeric_vector], n_results=n)


# ============================================================================
# Claude API äº’å‹•å‡½æ•¸
# ============================================================================
def analyze_intent(user_query):
    """
    ä½¿ç”¨ Claude åˆ†æä½¿ç”¨è€…æŸ¥è©¢æ„åœ–
    
    Args:
        user_query: ä½¿ç”¨è€…æŸ¥è©¢å­—ä¸²
        
    Returns:
        dict: åŒ…å« intent, search_text, numeric_filters çš„å­—å…¸
    """
    prompt = f"""åˆ†æé€™å€‹éŸ³æ¨‚æŸ¥è©¢çš„æ„åœ–,è¼¸å‡º JSON æ ¼å¼ï¼š

æŸ¥è©¢ï¼šã€Œ{user_query}ã€

è«‹è¼¸å‡ºï¼š
{{
    "intent": "artist/track/genre/mood/numeric",
    "search_text": "ç”¨æ–¼æª¢ç´¢çš„é—œéµå­—ï¼ˆè‹±æ–‡ï¼‰",
    "numeric_filters": {{
        "tempo_min": null æˆ–æ•¸å­—,
        "tempo_max": null æˆ–æ•¸å­—,
        "energy_min": null æˆ– 0-1,
        "energy_max": null æˆ– 0-1,
        "danceability_min": null æˆ– 0-1,
        "valence_min": null æˆ– 0-1,
        "valence_max": null æˆ– 0-1
    }}
}}

æ„åœ–åˆ¤æ–·ï¼š
- artistï¼šæ‰¾ç‰¹å®šæ­Œæ‰‹
- trackï¼šæ‰¾ç‰¹å®šæ­Œæ›²
- genreï¼šæ‰¾ç‰¹å®šé¡å‹ï¼ˆå¦‚ pop, rock, jazz, j-popï¼‰
- moodï¼šæ‰¾æƒ…å¢ƒ/å¿ƒæƒ…ï¼ˆå¦‚ æ”¾é¬†ã€é‹å‹•ã€æ‚²å‚·ï¼‰
- numericï¼šæ‰¾ç‰¹å®šéŸ³æ¨‚ç‰¹æ€§

åªè¼¸å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

    try:
        response = claude_client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=500,
            messages=[{"role": "user", "content": prompt}]
        )
        
        result = response.content[0].text
        result = result.replace("```json", "").replace("```", "").strip()
        return json.loads(result)
    except Exception as e:
        print(f"æ„åœ–åˆ†æå¤±æ•—: {e}")
        return {
            "intent": "combined", 
            "search_text": user_query, 
            "numeric_filters": {}
        }


def analyze_intent_with_context(user_query, session_history):
    """
    å¸¶å°è©±æ­·å²çš„æ„åœ–åˆ†æï¼ˆç”¨æ–¼å¤šè¼ªå°è©±ï¼‰
    
    Args:
        user_query: ä½¿ç”¨è€…æŸ¥è©¢
        session_history: å°è©±æ­·å²
        
    Returns:
        dict: æ„åœ–åˆ†æçµæœ
    """
    # æ§‹å»ºæ­·å²æ–‡å­—
    history_text = ""
    if session_history:
        history_text = "ä¹‹å‰çš„å°è©±ï¼š\n"
        for h in session_history[-6:]:  # åªä¿ç•™æœ€è¿‘ 6 è¼ª
            history_text += f"ä½¿ç”¨è€…ï¼š{h['user']}\n"
            history_text += f"æ¨è–¦é¡å‹ï¼š{h['genre']}\n"
            history_text += f"æ¨è–¦æ­Œæ›²ï¼š{h['songs']}\n\n"
    
    prompt = f"""{history_text}

ç¾åœ¨ä½¿ç”¨è€…èªªï¼šã€Œ{user_query}ã€

åˆ†æé€™å€‹éŸ³æ¨‚æŸ¥è©¢çš„æ„åœ–ï¼Œè¼¸å‡º JSON æ ¼å¼ï¼š
{{
    "intent": "artist/track/genre/mood/numeric",
    "search_text": "ç”¨æ–¼æª¢ç´¢çš„é—œéµå­—ï¼ˆè‹±æ–‡ï¼‰",
    "genre_filter": "ç²¾ç¢ºçš„é¡å‹åç¨±ï¼Œå¦‚æœæœ‰æŒ‡å®šçš„è©±ï¼ˆå¦‚ j-pop, rock, pop, jazz ç­‰ï¼‰ï¼Œå¦å‰‡ç‚º null",
    "numeric_filters": {{
        "tempo_min": null æˆ–æ•¸å­—,
        "tempo_max": null æˆ–æ•¸å­—,
        "energy_min": null æˆ– 0-1,
        "energy_max": null æˆ– 0-1,
        "danceability_min": null æˆ– 0-1,
        "valence_min": null æˆ– 0-1,
        "valence_max": null æˆ– 0-1
    }}
}}

é‡è¦æç¤ºï¼š
- æ—¥æœ¬æµè¡Œæ­Œ = j-popï¼ˆä¸æ˜¯ j-danceï¼‰
- éŸ“åœ‹æµè¡Œæ­Œ = k-pop
- å¦‚æœä½¿ç”¨è€…èªªã€Œé¡ä¼¼çš„ã€ã€Œå†çµ¦æˆ‘ã€ã€Œæ›ä¸€äº›ã€ï¼Œè«‹åƒè€ƒä¹‹å‰å°è©±çš„é¡å‹å’Œé¢¨æ ¼
- å¦‚æœä¹‹å‰æ¨è–¦çš„æ˜¯ j-popï¼Œã€Œé¡ä¼¼çš„ã€ä¹Ÿæ‡‰è©²æ˜¯ j-pop

åªè¼¸å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

    try:
        response = claude_client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=500,
            messages=[{"role": "user", "content": prompt}]
        )
        
        result = response.content[0].text
        result = result.replace("```json", "").replace("```", "").strip()
        return json.loads(result)
    except Exception as e:
        print(f"âš ï¸ æ„åœ–åˆ†æå¤±æ•—: {e}")
        return {
            "intent": "combined",
            "search_text": user_query,
            "genre_filter": None,
            "numeric_filters": {}
        }


def generate_recommendation(user_query, songs):
    """
    ä½¿ç”¨ Claude ç”Ÿæˆæ¨è–¦èªªæ˜
    
    Args:
        user_query: ä½¿ç”¨è€…æŸ¥è©¢
        songs: æ¨è–¦çš„æ­Œæ›²åˆ—è¡¨
        
    Returns:
        str: æ¨è–¦èªªæ˜æ–‡å­—
    """
    songs_text = "\n".join([
        f"{i+1}. {s['track_name']} - {s['artists']} "
        f"(é¡å‹:{s['track_genre']}, èƒ½é‡:{s['energy']:.2f}, ç¯€å¥:{s['tempo']:.0f}BPM)"
        for i, s in enumerate(songs[:10])
    ])
    
    prompt = f"""ä½¿ç”¨è€…æŸ¥è©¢ï¼šã€Œ{user_query}ã€

æ‰¾åˆ°çš„æ­Œæ›²ï¼š
{songs_text}

è«‹ç”¨ç¹é«”ä¸­æ–‡ç°¡çŸ­èªªæ˜ï¼ˆ2-3å¥ï¼‰ç‚ºä»€éº¼æ¨è–¦é€™äº›æ­Œ"""

    try:
        response = claude_client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=800,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆæ¨è–¦èªªæ˜å¤±æ•—: {e}")
        return "æ¨è–¦æ­Œæ›²å¦‚ä¸Šã€‚"


# ============================================================================
# è³‡æ–™è™•ç†å‡½æ•¸
# ============================================================================
def apply_numeric_filter(results, filters):
    """
    æ ¹æ“šæ•¸å€¼æ¢ä»¶éæ¿¾å€™é¸æ­Œæ›²
    
    Args:
        results: æª¢ç´¢çµæœ
        filters: æ•¸å€¼éæ¿¾æ¢ä»¶å­—å…¸
        
    Returns:
        list: éæ¿¾å¾Œçš„æ­Œæ›²åˆ—è¡¨
    """
    filtered = []
    
    for meta in results['metadatas'][0]:
        passed = True
        
        # æª¢æŸ¥å„é …æ¢ä»¶
        if filters.get('tempo_min') and meta['tempo'] < filters['tempo_min']:
            passed = False
        if filters.get('tempo_max') and meta['tempo'] > filters['tempo_max']:
            passed = False
        if filters.get('energy_min') and meta['energy'] < filters['energy_min']:
            passed = False
        if filters.get('energy_max') and meta['energy'] > filters['energy_max']:
            passed = False
        if filters.get('danceability_min') and meta['danceability'] < filters['danceability_min']:
            passed = False
        if filters.get('valence_min') and meta['valence'] < filters['valence_min']:
            passed = False
        if filters.get('valence_max') and meta['valence'] > filters['valence_max']:
            passed = False
        
        if passed:
            filtered.append(meta)
    
    return filtered


def remove_duplicates(songs):
    """
    å»é™¤é‡è¤‡æ­Œæ›²
    
    Args:
        songs: æ­Œæ›²åˆ—è¡¨
        
    Returns:
        list: å»é‡å¾Œçš„æ­Œæ›²åˆ—è¡¨
    """
    seen = set()
    unique = []
    
    for s in songs:
        key = f"{s['track_name']}_{s['artists']}"
        if key not in seen:
            seen.add(key)
            unique.append(s)
    
    return unique


# ============================================================================
# Log è¨˜éŒ„å‡½æ•¸
# ============================================================================
def write_log(user_query, intent_result, results_count, filtered_count, 
              final_songs, recommendation):
    """
    è¨˜éŒ„æŸ¥è©¢æ—¥èªŒ
    
    Args:
        user_query: ä½¿ç”¨è€…æŸ¥è©¢
        intent_result: æ„åœ–åˆ†æçµæœ
        results_count: å€™é¸æ•¸é‡
        filtered_count: éæ¿¾å¾Œæ•¸é‡
        final_songs: æœ€çµ‚æ¨è–¦æ­Œæ›²
        recommendation: æ¨è–¦èªªæ˜
    """
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    log_entry = f"""
{'='*60}
æ™‚é–“: {timestamp}
æŸ¥è©¢: {user_query}
æ„åœ–: {intent_result['intent']}
æª¢ç´¢é—œéµå­—: {intent_result['search_text']}
æ•¸å€¼éæ¿¾: {intent_result.get('numeric_filters', {})}
å€™é¸æ•¸é‡: {results_count}
éæ¿¾å¾Œæ•¸é‡: {filtered_count}
æ¨è–¦æ­Œæ›²:
"""
    for i, s in enumerate(final_songs):
        log_entry += f"  {i+1}. {s['track_name']} - {s['artists']}\n"
    
    log_entry += f"\nClaude æ¨è–¦èªªæ˜:\n{recommendation}\n"
    
    try:
        with open(LOG_PATH, "a", encoding="utf-8") as f:
            f.write(log_entry)
        print(f"ğŸ“ å·²è¨˜éŒ„åˆ° log")
    except Exception as e:
        print(f"âš ï¸ å¯«å…¥ log å¤±æ•—: {e}")


# ============================================================================
# ä¸»æ¨è–¦å‡½æ•¸
# ============================================================================

def recommend(user_query):
    """
    ä¸»æ¨è–¦å‡½æ•¸ï¼ˆåŠ å…¥è·¯ç”±åˆ¤æ–·ï¼‰
    """
    print(f"ğŸµ æŸ¥è©¢ï¼šã€Œ{user_query}ã€\n")
    
    # ğŸ”¥ Step 0.5: è·¯ç”±æ±ºç­–ï¼ˆæ–°å¢ï¼‰
    print("Step 0.5: è·¯ç”±æ±ºç­–...")
    decision = router.route_query(user_query)
    print(f"   æŸ¥è©¢é¡å‹: {decision.query_type.value}")
    print(f"   ä½¿ç”¨ Clustering: {'æ˜¯' if decision.use_clustering else 'å¦'}")
    print(f"   ä¿¡å¿ƒåˆ†æ•¸: {decision.confidence:.2f}")
    print(f"   åˆ¤æ–·ç†ç”±: {decision.reasoning}")
    
    # ğŸ”¥ åˆ¤æ–·æ˜¯å¦éœ€è¦ Clustering
    if decision.use_clustering and genre_clusters is not None:
        print("\n   â†’ å•Ÿå‹• Clustering å¤šæ­¥é©Ÿæª¢ç´¢")
        return recommend_with_clustering(user_query, decision)
    else:
        if decision.use_clustering and genre_clusters is None:
            print("\n   âš ï¸ Clustering æ¨¡å‹æœªè¼‰å…¥ï¼Œé™ç´šç‚ºå‘é‡æª¢ç´¢")
        else:
            print("\n   â†’ ä½¿ç”¨æ¨™æº–å‘é‡æª¢ç´¢")
        # ä½¿ç”¨åŸæœ‰é‚è¼¯
        return recommend_original(user_query)


def recommend_original(user_query):
    """
    ä¸»æ¨è–¦å‡½æ•¸ï¼ˆå–®æ¬¡æŸ¥è©¢ï¼‰
    
    Args:
        user_query: ä½¿ç”¨è€…æŸ¥è©¢
        
    Returns:
        list: æ¨è–¦çš„æ­Œæ›²åˆ—è¡¨
    """
    print(f"ğŸµ æŸ¥è©¢ï¼šã€Œ{user_query}ã€\n")
    
    # Step 1: æ„åœ–åˆ†æ
    print("Step 1: åˆ†ææ„åœ–...")
    intent_result = analyze_intent(user_query)
    print(f"   æ„åœ–: {intent_result['intent']}")
    print(f"   æª¢ç´¢é—œéµå­—: {intent_result['search_text']}")
    
    # Step 2: å‘é‡æª¢ç´¢
    print("\ntep 2: å‘é‡æª¢ç´¢...")
    intent = intent_result['intent']
    search_text = intent_result['search_text']
    
    if intent == 'artist':
        results = search_by_artist(search_text, n=CANDIDATE_SIZE)
    elif intent == 'track':
        results = search_by_track(search_text, n=CANDIDATE_SIZE)
    elif intent == 'genre':
        results = search_by_genre(search_text, n=CANDIDATE_SIZE)
    else:
        results = search_combined(search_text, n=CANDIDATE_SIZE)
    
    results_count = len(results['metadatas'][0])
    print(f"   æ‰¾åˆ° {results_count} é¦–å€™é¸æ­Œæ›²")
    
    # Step 3: æ•¸å€¼éæ¿¾
    print("\n Step 3: æ•¸å€¼éæ¿¾...")
    filters = intent_result.get('numeric_filters', {})
    filters = {k: v for k, v in filters.items() if v is not None}
    
    if filters:
        print(f"   éæ¿¾æ¢ä»¶: {filters}")
        filtered_songs = apply_numeric_filter(results, filters)
        filtered_count = len(filtered_songs)
        print(f"   éæ¿¾å¾Œ: {filtered_count} é¦–")
    else:
        print("   ç„¡æ•¸å€¼éæ¿¾")
        filtered_songs = results['metadatas'][0]
        filtered_count = len(filtered_songs)
    
    # å¦‚æœçµæœå¤ªå°‘ï¼Œä½¿ç”¨åŸå§‹çµæœ
    if len(filtered_songs) < 5:
        print("   çµæœå¤ªå°‘ï¼Œä½¿ç”¨åŸå§‹çµæœ")
        filtered_songs = results['metadatas'][0]
        filtered_count = len(filtered_songs)
    
    # Step 3.5: å»é‡è™•ç†
    print("\n Step 3.5: å»é‡è™•ç†...")
    unique_songs = remove_duplicates(filtered_songs)
    duplicate_count = len(filtered_songs) - len(unique_songs)
    
    if duplicate_count > 0:
        print(f"ç§»é™¤äº† {duplicate_count} é¦–é‡è¤‡æ­Œæ›²")
    else:
        print(f"ç„¡é‡è¤‡æ­Œæ›² âœ“")
    
    final_songs = unique_songs[:FINAL_RECOMMENDATION]
    
    # Step 4: ç”Ÿæˆæ¨è–¦
    print("\nStep 4: ç”Ÿæˆæ¨è–¦èªªæ˜...")
    recommendation = generate_recommendation(user_query, final_songs)
    
    # Step 5: å¯«å…¥ log
    write_log(user_query, intent_result, results_count, 
              filtered_count, final_songs, recommendation)
    
    print("\n" + "="*50)
    print(recommendation)
    
    return final_songs

def recommend_with_clustering(user_query, decision):
    """
    ä½¿ç”¨ Clustering çš„å¤šæ­¥é©Ÿæ¨è–¦
    å®Œå…¨åŸºæ–¼ tracks_df (parquet)ï¼Œä¸ä¾è³´ ChromaDB metadata
    
    Parameters:
    -----------
    user_query : str
        ä½¿ç”¨è€…æŸ¥è©¢
    decision : RoutingDecision
        è·¯ç”±æ±ºç­–çµæœ
    """
    
    print("\nğŸ”„ Clustering å¤šæ­¥é©Ÿæª¢ç´¢...")
    print(f"   æŸ¥è©¢é¡å‹: {decision.query_type.value}")
    
    query_type = decision.query_type
    extracted = decision.extracted_info
    
    # ============================================================
    # è·¯å¾‘ 1: è¿‘ä¼¼æ­Œæ›²æ¨è–¦
    # ============================================================
    if query_type == QueryType.SIMILARITY_TRACK:
        target_track = extracted.get('target_track', user_query)
        print(f"   â†’ ç›®æ¨™æ­Œæ›²: {target_track}")
        
        # Step 1: ç”¨ ChromaDB æ‰¾åˆ°æœ€ç›¸ä¼¼çš„æ­Œ
        print("\n   [Step 1] å¾å‘é‡è³‡æ–™åº«æ‰¾ç›®æ¨™æ­Œæ›²...")
        target_results = collections['track'].query(
            query_embeddings=[embedding_model.encode(target_track).tolist()],
            n_results=1
        )
        
        if not target_results['ids'][0]:
            print("   âš ï¸ æ‰¾ä¸åˆ°ç›®æ¨™æ­Œæ›²ï¼Œé™ç´šåˆ°åŸé‚è¼¯")
            return recommend_original(user_query)
        
        target_track_id = target_results['metadatas'][0][0]['track_id']
        target_track_name = target_results['metadatas'][0][0]['track_name']
        print(f"   âœ“ æ‰¾åˆ°: {target_track_name} (ID: {target_track_id})")
        
        # Step 2: å¾ parquet æŸ¥è©¢ cluster è³‡è¨Š
        print("\n   [Step 2] æŸ¥è©¢ cluster è³‡è¨Š...")
        track_info = tracks_df[tracks_df['track_id'] == target_track_id]
        
        if track_info.empty:
            print("   âš ï¸ parquet ä¸­æ‰¾ä¸åˆ°æ­¤æ­Œæ›²ï¼Œé™ç´šåˆ°åŸé‚è¼¯")
            return recommend_original(user_query)
        
        track_info = track_info.iloc[0]
        genre = track_info['track_genre']
        sub_cluster = track_info['sub_cluster']
        hierarchical_id = track_info.get('hierarchical_id', f"{genre}_cluster_{sub_cluster}")
        
        print(f"   âœ“ Cluster: {hierarchical_id}")
        print(f"      Genre: {genre}")
        print(f"      Sub-cluster: {sub_cluster}")
        
        # Step 3: å¾ parquet æ‰¾å‡ºåŒ cluster çš„æ‰€æœ‰æ­Œ
        print("\n   [Step 3] ç¯©é¸åŒ cluster æ­Œæ›²...")
        same_cluster = tracks_df[
            (tracks_df['track_genre'] == genre) &
            (tracks_df['sub_cluster'] == sub_cluster)
        ]
        
        print(f"   âœ“ åŒ cluster æ­Œæ›²æ•¸: {len(same_cluster)}")
        
        # å¦‚æœåŒ cluster æ­Œæ›²å¤ªå°‘ï¼Œæ“´å±•åˆ°ç›¸é„° cluster
        if len(same_cluster) < 20:
            print(f"   âš ï¸ æ­Œæ›²æ•¸å¤ªå°‘ï¼Œæ“´å±•åˆ°æ•´å€‹ {genre}")
            same_cluster = tracks_df[tracks_df['track_genre'] == genre]
            print(f"   âœ“ æ“´å±•å¾Œ: {len(same_cluster)} é¦–")
        
        # Step 4: åœ¨ ChromaDB æœå°‹ï¼Œä½†åªå¾åŒ cluster çš„æ­Œä¸­é¸
        print("\n   [Step 4] åœ¨ cluster å…§åšå‘é‡æª¢ç´¢...")
        cluster_track_ids = set(same_cluster['track_id'].tolist())
        
        # ç”¨ç›®æ¨™æ­Œæ›²åšç›¸ä¼¼åº¦æœå°‹
        all_results = collections['combined'].query(
            query_embeddings=[embedding_model.encode(target_track).tolist()],
            n_results=min(1000, len(cluster_track_ids) * 2)  # å¤šå–ä¸€äº›
        )
        
        # Step 5: éæ¿¾å‡ºåŒ cluster çš„æ­Œ
        filtered_songs = []
        for meta in all_results['metadatas'][0]:
            if meta['track_id'] in cluster_track_ids:
                # æ’é™¤ç›®æ¨™æ­Œæ›²æœ¬èº«
                if meta['track_id'] != target_track_id:
                    filtered_songs.append(meta)
            
            # å–å¤ äº†å°±åœæ­¢
            if len(filtered_songs) >= CANDIDATE_SIZE:
                break
        
        print(f"   âœ“ éæ¿¾å¾Œå€™é¸: {len(filtered_songs)} é¦–")
        
        # Step 6: å»é‡ã€å– Top K
        unique_songs = remove_duplicates(filtered_songs)
        final_songs = unique_songs[:FINAL_RECOMMENDATION]
        
        # Step 7: ç”Ÿæˆæ¨è–¦
        recommendation = generate_recommendation(user_query, final_songs)
        
        print("\n" + "="*50)
        print(recommendation)
        
        return final_songs
    
    
    # ============================================================
    # è·¯å¾‘ 2: è¿‘ä¼¼æ­Œæ‰‹æ¨è–¦
    # ============================================================
    elif query_type == QueryType.SIMILARITY_ARTIST:
        target_artist = extracted.get('target_artist', user_query)
        print(f"   â†’ ç›®æ¨™æ­Œæ‰‹: {target_artist}")
        
        # Step 1: æ‰¾åˆ°è©²æ­Œæ‰‹çš„æ‰€æœ‰æ­Œ
        print("\n   [Step 1] æ‰¾ç›®æ¨™æ­Œæ‰‹çš„æ­Œæ›²...")
        artist_results = collections['artist'].query(
            query_embeddings=[embedding_model.encode(target_artist).tolist()],
            n_results=30  # å–å‰ 30 é¦–è©²æ­Œæ‰‹çš„æ­Œ
        )
        
        if not artist_results['ids'][0]:
            print("   âš ï¸ æ‰¾ä¸åˆ°è©²æ­Œæ‰‹ï¼Œé™ç´šåˆ°åŸé‚è¼¯")
            return recommend_original(user_query)
        
        artist_track_ids = [meta['track_id'] for meta in artist_results['metadatas'][0]]
        print(f"   âœ“ æ‰¾åˆ° {len(artist_track_ids)} é¦–è©²æ­Œæ‰‹çš„æ­Œ")
        
        # Step 2: å¾ parquet çµ±è¨ˆæ­Œæ‰‹çš„ cluster åˆ†å¸ƒ
        print("\n   [Step 2] çµ±è¨ˆæ­Œæ‰‹çš„ cluster åˆ†å¸ƒ...")
        artist_tracks = tracks_df[tracks_df['track_id'].isin(artist_track_ids)]
        
        if artist_tracks.empty:
            print("   âš ï¸ parquet ä¸­æ‰¾ä¸åˆ°è©²æ­Œæ‰‹ï¼Œé™ç´šåˆ°åŸé‚è¼¯")
            return recommend_original(user_query)
        
        # çµ±è¨ˆæ¯å€‹ cluster çš„æ­Œæ›²æ•¸
        cluster_counts = artist_tracks.groupby(['track_genre', 'sub_cluster']).size()
        cluster_counts = cluster_counts.sort_values(ascending=False)
        
        print(f"   âœ“ æ­Œæ‰‹çš„ cluster åˆ†å¸ƒ:")
        for (genre, sub_cluster), count in cluster_counts.head(5).items():
            print(f"      - {genre}_cluster_{sub_cluster}: {count} é¦–")
        
        # Step 3: é¸æ“‡å‰ 2-3 å€‹ä¸»è¦ clusters
        top_clusters = cluster_counts.head(3).index.tolist()
        
        # Step 4: å¾é€™äº› clusters æ¨è–¦å…¶ä»–æ­Œæ‰‹çš„æ­Œ
        print("\n   [Step 3] å¾ä¸»è¦ clusters æ¨è–¦å…¶ä»–æ­Œæ‰‹...")
        cluster_songs = tracks_df[
            tracks_df.apply(
                lambda row: (row['track_genre'], row['sub_cluster']) in top_clusters,
                axis=1
            )
        ]
        
        # æ’é™¤åŸæ­Œæ‰‹çš„æ­Œ
        target_artist_lower = target_artist.lower()
        cluster_songs = cluster_songs[
            ~cluster_songs['artists'].str.lower().str.contains(target_artist_lower, na=False)
        ]
        
        print(f"   âœ“ å€™é¸æ­Œæ›²æ•¸: {len(cluster_songs)}")
        
        # Step 5: åœ¨ ChromaDB æœå°‹ï¼Œå¾å€™é¸ä¸­é¸æ“‡
        cluster_track_ids = set(cluster_songs['track_id'].tolist())
        
        all_results = collections['combined'].query(
            query_embeddings=[embedding_model.encode(target_artist).tolist()],
            n_results=min(1000, len(cluster_track_ids) * 2)
        )
        
        # éæ¿¾
        filtered_songs = []
        seen_artists = set()
        
        for meta in all_results['metadatas'][0]:
            if meta['track_id'] in cluster_track_ids:
                artist = meta['artists']
                
                # æ¯å€‹æ­Œæ‰‹æœ€å¤š 2 é¦–ï¼ˆç¢ºä¿å¤šæ¨£æ€§ï¼‰
                if seen_artists.count(artist) < 2:
                    filtered_songs.append(meta)
                    seen_artists.add(artist)
            
            if len(filtered_songs) >= CANDIDATE_SIZE:
                break
        
        print(f"   âœ“ éæ¿¾å¾Œå€™é¸: {len(filtered_songs)} é¦–")
        print(f"   âœ“ æ¶µè“‹ {len(set(seen_artists))} ä½ä¸åŒæ­Œæ‰‹")
        
        # Step 6: å»é‡ã€å– Top K
        unique_songs = remove_duplicates(filtered_songs)
        final_songs = unique_songs[:FINAL_RECOMMENDATION]
        
        # Step 7: ç”Ÿæˆæ¨è–¦
        recommendation = generate_recommendation(user_query, final_songs)
        
        print("\n" + "="*50)
        print(recommendation)
        
        return final_songs
    
    
    # ============================================================
    # è·¯å¾‘ 3: æ¢ç´¢åŒé¡å‹éŸ³æ¨‚
    # ============================================================
    elif query_type == QueryType.CLUSTER_EXPLORATION:
        print("   â†’ æ¢ç´¢æ¨¡å¼ï¼ˆå¾…å¯¦ä½œï¼‰")
        print("   âš ï¸ æš«æ™‚é™ç´šåˆ°åŸé‚è¼¯")
        return recommend_original(user_query)
    
    
    # ============================================================
    # å…¶ä»–ï¼šé™ç´šåˆ°åŸé‚è¼¯
    # ============================================================
    else:
        print("   â†’ æœªçŸ¥æŸ¥è©¢é¡å‹ï¼Œé™ç´šåˆ°åŸé‚è¼¯")
        return recommend_original(user_query)

def chat_recommend(user_message, session_id):
    """
    èŠå¤©å¼æ¨è–¦ï¼ˆå¤šè¼ªå°è©±ï¼‰
    
    Args:
        user_message: ä½¿ç”¨è€…è¨Šæ¯
        session_id: å°è©± session ID
        
    Returns:
        str: æ¨è–¦èªªæ˜æ–‡å­—
    """
    # åˆå§‹åŒ– session
    if session_id not in chat_sessions:
        chat_sessions[session_id] = []
    
    session_history = chat_sessions[session_id]
    
    # æ”¶é›†å·²æ¨è–¦éçš„æ­Œæ›²
    recommended_songs = set()
    for h in session_history:
        for song in h['songs'].split(', '):
            recommended_songs.add(song.strip())
    
    # æ„åœ–åˆ†æï¼ˆå¸¶æ­·å²ï¼‰
    intent_result = analyze_intent_with_context(user_message, session_history)
    
    intent = intent_result['intent']
    search_text = intent_result['search_text']
    
    # å‘é‡æª¢ç´¢
    if intent == 'artist':
        results = search_by_artist(search_text, n=CANDIDATE_SIZE)
    elif intent == 'track':
        results = search_by_track(search_text, n=CANDIDATE_SIZE)
    elif intent == 'genre':
        results = search_by_genre(search_text, n=CANDIDATE_SIZE)
    else:
        results = search_combined(search_text, n=CANDIDATE_SIZE)
    
    # å¦‚æœæœ‰ç²¾ç¢ºé¡å‹éæ¿¾
    genre_filter = intent_result.get('genre_filter')
    if genre_filter:
        results = search_by_genre(genre_filter, n=CANDIDATE_SIZE)
    
    # æ•¸å€¼éæ¿¾
    filters = intent_result.get('numeric_filters', {})
    filters = {k: v for k, v in filters.items() if v is not None}
    
    if filters:
        filtered_songs = apply_numeric_filter(results, filters)
    else:
        filtered_songs = results['metadatas'][0]
    
    if len(filtered_songs) < 5:
        filtered_songs = results['metadatas'][0]
    
    # å»é‡
    filtered_songs = remove_duplicates(filtered_songs)
    
    # æ’é™¤å·²æ¨è–¦éçš„æ­Œ
    new_songs = [s for s in filtered_songs 
                 if s['track_name'] not in recommended_songs]
    
    # å¦‚æœæ–°æ­Œä¸å¤ ï¼Œæ‰ç”¨èˆŠçš„è£œ
    if len(new_songs) < FINAL_RECOMMENDATION:
        final_songs = new_songs + [
            s for s in filtered_songs 
            if s['track_name'] in recommended_songs
        ][:FINAL_RECOMMENDATION - len(new_songs)]
    else:
        final_songs = new_songs[:FINAL_RECOMMENDATION]
    
    # ç”Ÿæˆæ¨è–¦
    recommendation = generate_recommendation(user_message, final_songs)
    
    # æ›´æ–°æ­·å²
    songs_summary = ", ".join([s['track_name'] for s in final_songs])
    genre_summary = final_songs[0]['track_genre'] if final_songs else ""
    session_history.append({
        "user": user_message,
        "genre": genre_summary,
        "songs": songs_summary
    })
    chat_sessions[session_id] = session_history
    
    # å¯«å…¥ log
    write_log(user_message, intent_result, len(results['metadatas'][0]),
              len(filtered_songs), final_songs, recommendation)
    
    return recommendation


# ============================================================================
# Gradio ä»‹é¢
# ============================================================================
def create_gradio_interface():
    """å»ºç«‹ Gradio èŠå¤©ä»‹é¢"""
    
    def user_message(message, history):
        """è™•ç†ä½¿ç”¨è€…è¨Šæ¯"""
        if not message.strip():
            return "", history
        history.append((message, None))
        return "", history
    
    def bot_response(history, session_state):
        """ç”Ÿæˆæ©Ÿå™¨äººå›æ‡‰"""
        if session_state is None:
            session_state = str(uuid.uuid4())
        
        user_msg = history[-1][0]
        response = chat_recommend(user_msg, session_state)
        history[-1] = (user_msg, response)
        return history, session_state
    
    def clear_chat(session_state):
        """æ¸…é™¤å°è©±"""
        if session_state and session_state in chat_sessions:
            chat_sessions[session_state] = []
        return [], session_state
    
    # å»ºç«‹ä»‹é¢
    with gr.Blocks(title="ğŸµ Spotify éŸ³æ¨‚æ¨è–¦ç³»çµ±", 
                   css="footer {display: none}") as demo:
        gr.Markdown("# ğŸµ Spotify éŸ³æ¨‚æ¨è–¦ç³»çµ±")
        gr.Markdown("è¼¸å…¥ä½ æƒ³æ‰¾çš„éŸ³æ¨‚é¡å‹ã€æ­Œæ‰‹ã€å¿ƒæƒ…æˆ–æƒ…å¢ƒï¼Œæˆ‘æœƒæ¨è–¦é©åˆçš„æ­Œæ›²ï¼")
        
        session_state = gr.State(None)
        chatbot = gr.Chatbot(height=500, container=True, show_copy_button=True)
        
        with gr.Row(equal_height=True):
            msg = gr.Textbox(
                label="",
                placeholder="ä¾‹å¦‚ï¼šçµ¦æˆ‘æ—¥æœ¬æµè¡Œæ­Œ",
                scale=6,
                container=False
            )
            submit = gr.Button("é€å‡º", scale=1, min_width=80)
        
        clear = gr.Button("æ¸…é™¤å°è©±", variant="secondary")
        
        # ç¶å®šäº‹ä»¶
        submit.click(
            user_message, [msg, chatbot], [msg, chatbot]
        ).then(
            bot_response, [chatbot, session_state], [chatbot, session_state]
        )
        
        msg.submit(
            user_message, [msg, chatbot], [msg, chatbot]
        ).then(
            bot_response, [chatbot, session_state], [chatbot, session_state]
        )
        
        clear.click(clear_chat, [session_state], [chatbot, session_state])
    
    return demo


# ============================================================================
# ä¸»ç¨‹å¼ï¼ˆæœ¬æ©Ÿ VS Code ç‰ˆæœ¬ï¼‰
# ============================================================================
def main():
    global chroma_client, collections, router, genre_clusters, tracks_df
    
    print("=" * 80)
    print("ğŸµ Spotify éŸ³æ¨‚æ¨è–¦ç³»çµ± v2.0 - æ•´åˆ Clustering è·¯ç”±")
    print("=" * 80)

    # ============================================================
    # Step 1: ç¢ºèªæª”æ¡ˆå­˜åœ¨
    # ============================================================
    print("\nStep 1: æª¢æŸ¥å¿…è¦æª”æ¡ˆ...")
    
    if not os.path.exists(DATA_PATH):
        print(f"âŒ æ‰¾ä¸åˆ° dataset.csvï¼š{DATA_PATH}")
        return

    if not os.path.exists(DB_PATH):
        print(f"âŒ æ‰¾ä¸åˆ° ChromaDBï¼š{DB_PATH}")
        return
    
    print("âœ“ æ‰€æœ‰æª”æ¡ˆå­˜åœ¨")

    # ============================================================
    # Step 2: è¼‰å…¥å‘é‡è³‡æ–™åº«
    # ============================================================
    print("\nStep 2: è¼‰å…¥å‘é‡è³‡æ–™åº«...")
    chroma_client, collections = initialize_chromadb(DB_PATH)
    print("âœ“ å‘é‡è³‡æ–™åº«è¼‰å…¥å®Œæˆ")

    # ============================================================
    # Step 3: åˆå§‹åŒ–è·¯ç”±å™¨
    # ============================================================
    print("\nStep 3: åˆå§‹åŒ–æŸ¥è©¢è·¯ç”±å™¨...")
    router = QueryRouter()
    print("âœ“ è·¯ç”±å™¨åˆå§‹åŒ–å®Œæˆ")

    # ============================================================
    # Step 4: è¼‰å…¥ Clustering æ¨¡å‹
    # ============================================================
    cluster_path = os.path.join(DRIVE_ROOT, "models/genre_clusters_v3.pkl")
    tracks_path = os.path.join(DRIVE_ROOT, "data/tracks_with_hierarchical_clusters_v3.parquet")
    
    print("\nStep 4: è¼‰å…¥ Clustering æ¨¡å‹...")
    
    if os.path.exists(tracks_path):
        tracks_df = pd.read_parquet(tracks_path)
        print(f"âœ“ å·²è¼‰å…¥ {len(tracks_df):,} é¦–æ­Œæ›²è³‡æ–™")
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_cols = ['track_id', 'track_genre', 'sub_cluster']
        missing_cols = [col for col in required_cols if col not in tracks_df.columns]
        
        if missing_cols:
            print(f"âš ï¸ ç¼ºå°‘æ¬„ä½: {missing_cols}")
            tracks_df = None
        else:
            print(f"âœ“ å¿…è¦æ¬„ä½æª¢æŸ¥é€šé")
            
            # å¦‚æœæ²’æœ‰ hierarchical_idï¼Œå°±å‰µå»ºä¸€å€‹
            if 'hierarchical_id' not in tracks_df.columns:
                print("  â†’ å‰µå»º hierarchical_id æ¬„ä½...")
                tracks_df['hierarchical_id'] = (
                    tracks_df['track_genre'] + '_cluster_' + 
                    tracks_df['sub_cluster'].astype(str)
                )
                print("  âœ“ hierarchical_id å‰µå»ºå®Œæˆ")
            
            # é¡¯ç¤º cluster çµ±è¨ˆ
            n_genres = tracks_df['track_genre'].nunique()
            n_clusters = tracks_df.groupby('track_genre')['sub_cluster'].nunique().sum()
            print(f"âœ“ çµ±è¨ˆ: {n_genres} å€‹ genres, {n_clusters} å€‹ sub-clusters")
    else:
        print(f"âš ï¸ æ‰¾ä¸åˆ° parquet æª”æ¡ˆï¼š{tracks_path}")
        tracks_df = None
    
    if os.path.exists(cluster_path):
        genre_clusters = joblib.load(cluster_path)
        print(f"âœ“ å·²è¼‰å…¥ {len(genre_clusters)} å€‹ genre cluster æ¨¡å‹")
    else:
        print(f"âš ï¸ æ‰¾ä¸åˆ° cluster æ¨¡å‹ï¼š{cluster_path}")
        genre_clusters = None

    # ============================================================
    # ç³»çµ±ç‹€æ…‹ç¸½çµ
    # ============================================================
    print("\n" + "=" * 80)
    print("âœ… ç³»çµ±å•Ÿå‹•å®Œæˆï¼")
    print("=" * 80)
    print("\nç³»çµ±åŠŸèƒ½ç‹€æ…‹:")
    print(f"  âœ“ å‘é‡æª¢ç´¢: å¯ç”¨")
    print(f"  {'âœ“' if tracks_df is not None else 'âœ—'} Clustering æª¢ç´¢: {'å¯ç”¨' if tracks_df is not None else 'ä¸å¯ç”¨'}")
    print(f"  âœ“ æ™ºèƒ½è·¯ç”±: å¯ç”¨")
    print("=" * 80)

    # ============================================================
    # Step 5: æ¸¬è©¦æ¨è–¦åŠŸèƒ½
    # ============================================================
    print("\nğŸ§ª é–‹å§‹æ¸¬è©¦æ¨è–¦åŠŸèƒ½...\n")
    
    test_queries = [
        # åŸºç¤æŸ¥è©¢ï¼ˆä¸éœ€è¦ clusteringï¼‰
        "çµ¦æˆ‘é©åˆé‹å‹•çš„éŸ³æ¨‚",
        "Taylor Swift çš„æ­Œ",
        
        # Clustering æŸ¥è©¢ï¼ˆéœ€è¦ clusteringï¼‰
        "é¡ä¼¼ Bohemian Rhapsody çš„æ­Œ",
        "æ¨è–¦åƒ Adele çš„æ­Œæ‰‹",
    ]
    
    for idx, query in enumerate(test_queries, 1):
        print("\n" + "=" * 80)
        print(f"[æ¸¬è©¦ {idx}/{len(test_queries)}] æŸ¥è©¢: ã€Œ{query}ã€")
        print("=" * 80)
        
        try:
            songs = recommend(query)
            
            if songs:
                print(f"\nâœ… æ¨è–¦çµæœï¼ˆå…± {len(songs)} é¦–ï¼‰:")
                for i, song in enumerate(songs[:5], 1):
                    genre = song.get('track_genre', 'Unknown')
                    print(f"  {i}. {song['track_name']} - {song['artists']} [{genre}]")
                
                if len(songs) > 5:
                    print(f"  ... é‚„æœ‰ {len(songs) - 5} é¦–")
            else:
                print("\nâš ï¸ æ²’æœ‰æ‰¾åˆ°æ¨è–¦çµæœ")
        
        except Exception as e:
            print(f"\nâŒ éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
        
        # é¿å… API rate limit
        if idx < len(test_queries):
            print("\nâ³ ç­‰å¾… 2 ç§’...")
            time.sleep(2)
    
    # ============================================================
    # å®Œæˆ
    # ============================================================
    print("\n" + "=" * 80)
    print("ğŸ‰ æ¸¬è©¦å®Œæˆï¼")
    print("=" * 80)
    
    # æä¾›äº’å‹•å¼æ¸¬è©¦é¸é …
    print("\nğŸ’¡ æç¤º:")
    print("  - æ‰€æœ‰æ¸¬è©¦å·²å®Œæˆ")
    print("  - å¦‚éœ€äº’å‹•æ¸¬è©¦ï¼Œè«‹ä½¿ç”¨ Gradio ä»‹é¢")
    print("  - å¦‚éœ€èª¿æ•´ clusteringï¼Œè«‹ä¿®æ”¹ parquet æª”æ¡ˆå¾Œé‡æ–°è¼‰å…¥")


if __name__ == "__main__":
    main()