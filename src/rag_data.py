import os
import json
import shutil
from openai import OpenAI
from dotenv import load_dotenv, find_dotenv
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.schema import BaseRetriever, Document
from langchain_anthropic import ChatAnthropic
from typing import List, Any
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain
import pandas as pd



def process_spotify_csv(csv_path, limit=None):
    """
    è®€å– Spotify CSV ä¸¦è½‰æ›æˆæ–‡å­—æè¿°
    """
    df = pd.read_csv(csv_path)


    if limit:
        df = df.head(limit)
        print(f"é™åˆ¶è™•ç†å‰ {limit} ç­†è³‡æ–™")
    
    documents = []
    
    for idx, row in df.iterrows():
        # æ–¹æ³• 1ï¼šåˆ†æ¬„ä½æè¿°ï¼ˆæ¨è–¦ï¼‰
        text = f"""
        ARTIST: {row['artists']}
        TRACK: {row['track_name']}
        ALBUM: {row['album_name']}
        GENRE: {row['track_genre']}
        
        éŸ³æ¨‚ç‰¹æ€§ï¼š
        - ç¯€å¥æ„Ÿ (Danceability): {row['danceability']:.2f}
        - èƒ½é‡ (Energy): {row['energy']:.2f}
        - éŸ¿åº¦ (Loudness): {row['loudness']:.1f} dB
        - é€Ÿåº¦ (Tempo): {row['tempo']:.0f} BPM
        - æ­£é¢æƒ…ç·’ (Valence): {row['valence']:.2f}
        - ç†±é–€åº¦ (Popularity): {row['popularity']}/100
        """.strip()
        
        # ä¿ç•™åŸå§‹æ•¸å€¼ä½œç‚º metadataï¼ˆé‡è¦ï¼ï¼‰
        metadata = {
            'track_id': row['track_id'],
            'artists': row['artists'],
            'track_name': row['track_name'],
            'album_name': row['album_name'],
            'track_genre': row['track_genre'],
            'popularity': float(row['popularity']),
            'danceability': float(row['danceability']),
            'energy': float(row['energy']),
            'loudness': float(row['loudness']),
            'tempo': float(row['tempo']),
            'valence': float(row['valence']),
            'speechiness': float(row['speechiness']),
            'acousticness': float(row['acousticness']),
            'instrumentalness': float(row['instrumentalness']),
        }
        
        documents.append(Document(
            page_content=text,
            metadata=metadata
        ))
    
    return documents

def setup_environment_with_csv(csv_path,  limit=None):
    """
    å®Œæ•´è¨­å®šï¼šè¼‰å…¥ CSV + å»ºç«‹å‘é‡è³‡æ–™åº« + åˆå§‹åŒ– Claude
    """
    _ = load_dotenv(find_dotenv())
    
    # 1. åˆå§‹åŒ– Claude LLM
    llm = ChatAnthropic(
        model="claude-sonnet-4-20250514", 
        temperature=0,
        api_key=os.environ['ANTHROPIC_API_KEY']
    )
    
    # 2. åˆå§‹åŒ– Embeddingï¼ˆç”¨ OpenAIï¼‰
    embeddings = OpenAIEmbeddings(
        api_key=os.environ['OPENAI_API_KEY']
    )
    
    # 3. è™•ç† CSV
    print("è™•ç† Spotify CSV...")
    documents = process_spotify_csv(csv_path, limit=limit)
    print(f"æˆåŠŸè™•ç† {len(documents)} é¦–æ­Œæ›²")
    
    # 4. å»ºç«‹å‘é‡è³‡æ–™åº«
    print("å»ºç«‹å‘é‡è³‡æ–™åº«...")
    vectordb = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        persist_directory="./spotify_chroma_db"
    )
    print("å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆï¼")
    
    return llm, vectordb, documents



def rag_music_recommendation(llm, vectordb, user_query):
    """
    æ··åˆæª¢ç´¢ï¼šå‘é‡ç›¸ä¼¼åº¦ + æ•¸å€¼éæ¿¾
    """
    
    # Step 1: Claude åˆ†ææ„åœ–ä¸¦æå–æ•¸å€¼æ¢ä»¶
    intent_prompt = f"""
    ä½¿ç”¨è€…æŸ¥è©¢ï¼šã€Œ{user_query}ã€
    
    è«‹åˆ†æé€™å€‹æŸ¥è©¢ï¼Œä¸¦ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼š
    {{
      "intent": "æŸ¥è©¢æ„åœ–é¡å‹ï¼ˆartist/genre/mood/activityï¼‰",
      "keywords": ["é—œéµå­—1", "é—œéµå­—2"],
      "numeric_filters": {{
        "tempo_min": æ•¸å­—æˆ–null,
        "energy_min": æ•¸å­—æˆ–null,
        "danceability_min": æ•¸å­—æˆ–null,
        "valence_min": æ•¸å­—æˆ–null,
        "acousticness_max": æ•¸å­—æˆ–null
      }}
    }}
    
    åªè¼¸å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
    """
    
    intent_response = llm.invoke(intent_prompt)
    print(f"ğŸ¤– æ„åœ–åˆ†æï¼š\n{intent_response.content}\n")
    
    # è§£æ JSONï¼ˆè™•ç†å¯èƒ½çš„ markdown åŒ…è£¹ï¼‰
    try:
        intent_text = intent_response.content.strip()
        if intent_text.startswith("```json"):
            intent_text = intent_text.split("```json")[1].split("```")[0].strip()
        intent_data = json.loads(intent_text)
    except:
        intent_data = {"numeric_filters": {}}
    
    # Step 2: å‘é‡æª¢ç´¢ï¼ˆå…ˆæ‰¾å€™é¸æ­Œæ›²ï¼‰
    candidates = vectordb.similarity_search(user_query, k=50)  # å¤šæ‰¾ä¸€äº›å€™é¸
    print(f"ğŸ“Š å‘é‡æª¢ç´¢æ‰¾åˆ° {len(candidates)} é¦–å€™é¸æ­Œæ›²")
    
    # Step 3: æ•¸å€¼éæ¿¾
    filters = intent_data.get("numeric_filters", {})
    filtered_results = []
    
    for doc in candidates:
        # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæ‰€æœ‰æ•¸å€¼æ¢ä»¶
        if filters.get("tempo_min") and doc.metadata['tempo'] < filters['tempo_min']:
            continue
        if filters.get("energy_min") and doc.metadata['energy'] < filters['energy_min']:
            continue
        if filters.get("danceability_min") and doc.metadata['danceability'] < filters['danceability_min']:
            continue
        if filters.get("valence_min") and doc.metadata['valence'] < filters['valence_min']:
            continue
        if filters.get("acousticness_max") and doc.metadata['acousticness'] > filters['acousticness_max']:
            continue
        
        filtered_results.append(doc)
        
        if len(filtered_results) >= 10:  # åªè¦ 10 é¦–å°±å¤ 
            break
    
    print(f"âœ… æ•¸å€¼éæ¿¾å¾Œå‰©ä¸‹ {len(filtered_results)} é¦–æ­Œæ›²")
    
    # Step 4: çµ„ç¹”æª¢ç´¢çµæœ
    final_songs = filtered_results[:5]
    context = "\n\n".join([
        f"æ­Œæ›² {i+1}: {doc.metadata['track_name']} - {doc.metadata['artists']}\n"
        f"é¡å‹: {doc.metadata['track_genre']}\n"
        f"ç‰¹æ€§: èƒ½é‡ {doc.metadata['energy']:.2f}, ç¯€å¥æ„Ÿ {doc.metadata['danceability']:.2f}, "
        f"é€Ÿåº¦ {doc.metadata['tempo']:.0f} BPM, æ­£é¢æƒ…ç·’ {doc.metadata['valence']:.2f}"
        for i, doc in enumerate(final_songs)
    ])
    
    # Step 5: Claude ç”Ÿæˆæ¨è–¦èªªæ˜
    recommendation_prompt = f"""
    ä½¿ç”¨è€…å•ï¼šã€Œ{user_query}ã€
    
    æ ¹æ“šä»¥ä¸‹æª¢ç´¢åˆ°çš„æ­Œæ›²ï¼Œç”Ÿæˆæ¨è–¦ç†ç”±ï¼š
    
    {context}
    
    è«‹ç”¨å‹å–„ã€ç°¡æ½”çš„æ–¹å¼æ¨è–¦é€™äº›æ­Œæ›²ï¼Œèªªæ˜ç‚ºä»€éº¼é©åˆä½¿ç”¨è€…çš„éœ€æ±‚ã€‚
    """
    
    recommendation = llm.invoke(recommendation_prompt)
    
    return {
        'songs': final_songs,
        'explanation': recommendation.content,
        'intent': intent_data
    }


if __name__ == "__main__":

    '''for building vectorDB'''

    # db_path = "./spotify_chroma_db"
    # if os.path.exists(db_path):
    #     shutil.rmtree(db_path)
    #     print("âœ… å·²åˆªé™¤èˆŠçš„å‘é‡è³‡æ–™åº«")


    # llm, vectordb, docs = setup_environment_with_csv(
    #     "/Users/mangtinglee/Desktop/UT/data mining/æœŸæœ«/dataset.csv",
    #     limit=5000,
    # )

    '''for reading only'''
    _ = load_dotenv(find_dotenv())
    embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])
    llm = ChatAnthropic(
        model="claude-sonnet-4-20250514",
        temperature=0,
        api_key=os.environ['ANTHROPIC_API_KEY']
    )
    
    # è¼‰å…¥å·²å­˜åœ¨çš„å‘é‡è³‡æ–™åº«
    vectordb = Chroma(
        persist_directory="./spotify_chroma_db",
        embedding_function=embeddings
    )

    print(f"âœ… è¼‰å…¥å‘é‡è³‡æ–™åº«å®Œæˆï¼Œå…± {vectordb._collection.count()} é¦–æ­Œ")


    # ===== ä½¿ç”¨æ–°çš„æ··åˆæª¢ç´¢å‡½æ•¸ =====
    result = rag_music_recommendation(
        llm, 
        vectordb, 
        "æˆ‘æƒ³æ‰¾é©åˆæ¸…æ™¨æ•£æ­¥ç”¨çš„æ­Œ"
    )
    
    print("\nğŸµ æ¨è–¦çµæœï¼š")
    print(result['explanation'])
    
    print("\nğŸ“‹ æ¨è–¦æ­Œæ›²åˆ—è¡¨ï¼š")
    for i, doc in enumerate(result['songs'], 1):
        print(f"\n{i}. {doc.metadata['track_name']} - {doc.metadata['artists']}")
        print(f"   é¡å‹: {doc.metadata['track_genre']}")
        print(f"   èƒ½é‡: {doc.metadata['energy']:.2f} | ç¯€å¥: {doc.metadata['danceability']:.2f}")
        print(f"   é€Ÿåº¦: {doc.metadata['tempo']:.0f} BPM | è²å­¸æ€§: {doc.metadata['acousticness']:.2f}")
