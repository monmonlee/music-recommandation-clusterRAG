# query_router.py (ç¨ç«‹æª”æ¡ˆ)
"""
Query Router - æ™ºèƒ½æŸ¥è©¢è·¯ç”±ç³»çµ±
"""

import json
from enum import Enum
from typing import Dict, Optional
from dataclasses import dataclass
import anthropic
import os
from dotenv import load_dotenv, find_dotenv

class QueryType(Enum):
    """æŸ¥è©¢é¡å‹å®šç¾©"""
    CONTEXT_SEARCH = "context_search"      # æƒ…å¢ƒæœå°‹
    DIRECT_SEARCH = "direct_search"        # ç›´æ¥æŸ¥è©¢
    SIMILARITY_TRACK = "similarity_track"  # è¿‘ä¼¼æ­Œæ›²
    SIMILARITY_ARTIST = "similarity_artist" # è¿‘ä¼¼æ­Œæ‰‹
    CLUSTER_EXPLORATION = "cluster_exploration"

@dataclass
class RoutingDecision:
    """è·¯ç”±æ±ºç­–çµæœ"""
    query_type: QueryType
    use_clustering: bool
    extracted_info: Dict
    reasoning: str
    confidence: float

class QueryRouter:
    def __init__(self, api_key: Optional[str] = None):
        _ = load_dotenv(find_dotenv())
        self.client = anthropic.Anthropic(
            api_key=os.environ['ANTHROPIC_API_KEY']
        )
        self.model = "claude-3-5-haiku-20241022"
    
    def route_query(self, user_query: str) -> RoutingDecision:
        """åˆ†ææŸ¥è©¢ä¸¦æ±ºå®šè·¯ç”±"""
        prompt = self._build_routing_prompt(user_query)
        
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1000,
                temperature=0,
                messages=[{"role": "user", "content": prompt}]
            )
            
            return self._parse_llm_response(response.content[0].text)
            
        except Exception as e:
            print(f"âš ï¸ è·¯ç”±éŒ¯èª¤: {e}")
            return RoutingDecision(
                query_type=QueryType.DIRECT_SEARCH,
                use_clustering=False,
                extracted_info={"original_query": user_query},
                reasoning="è·¯ç”±å™¨éŒ¯èª¤ï¼Œä½¿ç”¨é è¨­ç­–ç•¥",
                confidence=0.0
            )
    
    def _build_routing_prompt(self, user_query: str) -> str:
        return f"""ä½ æ˜¯éŸ³æ¨‚æ¨è–¦ç³»çµ±çš„æŸ¥è©¢åˆ†é¡å°ˆå®¶ã€‚è«‹åˆ†æä½¿ç”¨è€…æŸ¥è©¢ä¸¦åˆ¤æ–·æª¢ç´¢ç­–ç•¥ã€‚

## æŸ¥è©¢é¡å‹å®šç¾©

1. **context_search** (æƒ…å¢ƒæœå°‹)
   - ç‰¹å¾µ: æè¿°å¿ƒæƒ…ã€å ´æ™¯ã€æ°›åœã€æ´»å‹•
   - ç¯„ä¾‹: ã€Œé©åˆé‹å‹•çš„éŸ³æ¨‚ã€ã€Œæƒ³è½æ‚²å‚·çš„æ­Œã€ã€Œæ—©æ™¨å’–å•¡å»³ã€
   - ç­–ç•¥: å‘é‡èªç¾©æœå°‹(ä¸éœ€ clustering)

2. **direct_search** (ç›´æ¥æŸ¥è©¢)
   - ç‰¹å¾µ: æ˜ç¢ºæ­Œåã€æ­Œæ‰‹ã€å°ˆè¼¯
   - ç¯„ä¾‹: ã€ŒTaylor Swiftã€ã€Œæ’­æ”¾ Shake It Offã€ã€Œçµ¦æˆ‘æ—¥æœ¬æµè¡Œæ­Œã€
   - ç­–ç•¥: å‘é‡ç²¾ç¢ºåŒ¹é…(ä¸éœ€ clustering)

3. **similarity_track** (è¿‘ä¼¼æ¨è–¦-æ­Œæ›²)
   - ç‰¹å¾µ: æƒ³æ‰¾ã€Œé¡ä¼¼æŸé¦–æ­Œã€çš„éŸ³æ¨‚
   - é—œéµå­—: é¡ä¼¼ã€åƒã€ç›¸ä¼¼ã€åŒé¢¨æ ¼ + æ­Œå
   - ç¯„ä¾‹: ã€Œé¡ä¼¼ Bohemian Rhapsody çš„æ­Œã€ã€Œè·Ÿé€™é¦–é¢¨æ ¼æ¥è¿‘çš„ã€
   - ç­–ç•¥: **éœ€è¦ clustering**

4. **similarity_artist** (è¿‘ä¼¼æ¨è–¦-æ­Œæ‰‹)
   - ç‰¹å¾µ: æƒ³æ‰¾ã€Œé¡ä¼¼æŸæ­Œæ‰‹ã€çš„éŸ³æ¨‚
   - é—œéµå­—: é¡ä¼¼ã€åƒã€é¢¨æ ¼æ¥è¿‘ + æ­Œæ‰‹å
   - ç¯„ä¾‹: ã€Œæ¨è–¦é¡ä¼¼ Adele çš„æ­Œæ‰‹ã€ã€Œè·Ÿ Ed Sheeran é¢¨æ ¼æ¥è¿‘çš„ã€
   - ç­–ç•¥: **éœ€è¦ clustering**

5. **cluster_exploration** (æ¢ç´¢åŒé¡å‹)
   - ç‰¹å¾µ: æ¢ç´¢æŸé¢¨æ ¼ã€æµæ´¾
   - é—œéµå­—: åŒé¡å‹ã€é€™ä¸€ç¾¤ã€ç›¸åŒé¢¨æ ¼ã€æ›´å¤šé€™ç¨®
   - ç¯„ä¾‹: ã€Œæ›´å¤šé€™ç¨®é¢¨æ ¼çš„æ­Œã€ã€ŒåŒé¡å‹çš„éŸ³æ¨‚ã€
   - ç­–ç•¥: **éœ€è¦ clustering**

## ä½¿ç”¨è€…æŸ¥è©¢
ã€Œ{user_query}ã€

## è¼¸å‡ºæ ¼å¼(å¿…é ˆæ˜¯æœ‰æ•ˆ JSON)

{{
  "query_type": "é¸æ“‡ä¸Šè¿°äº”ç¨®é¡å‹ä¹‹ä¸€",
  "use_clustering": true/false,
  "extracted_info": {{
    "target_track": "è‹¥æ˜¯ similarity_trackï¼Œæå–æ­Œåï¼Œå¦å‰‡ null",
    "target_artist": "è‹¥æ˜¯ similarity_artistï¼Œæå–æ­Œæ‰‹åï¼Œå¦å‰‡ null",
    "context_keywords": ["è‹¥æ˜¯ context_searchï¼Œæå–é—œéµæƒ…å¢ƒè©"],
    "original_query": "{user_query}"
  }},
  "reasoning": "ç°¡çŸ­èªªæ˜åˆ¤æ–·ç†ç”±(1-2å¥)",
  "confidence": 0.0-1.0 çš„ä¿¡å¿ƒåˆ†æ•¸
}}

è«‹ç›´æ¥è¼¸å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–èªªæ˜æ–‡å­—ã€‚"""

    def _parse_llm_response(self, llm_output: str) -> RoutingDecision:
        """è§£æ LLM JSON å›æ‡‰"""
        try:
            cleaned = llm_output.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[7:]
            if cleaned.startswith("```"):
                cleaned = cleaned[3:]
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()
            
            result = json.loads(cleaned)
            
            return RoutingDecision(
                query_type=QueryType(result["query_type"]),
                use_clustering=result["use_clustering"],
                extracted_info=result["extracted_info"],
                reasoning=result["reasoning"],
                confidence=result["confidence"]
            )
        except Exception as e:
            print(f"âŒ è§£æå¤±æ•—: {e}\nåŸå§‹å›æ‡‰: {llm_output}")
            raise


# æ¸¬è©¦ç”¨ä¸»ç¨‹å¼
if __name__ == "__main__":
    router = QueryRouter()
    
    test_queries = [
        "é©åˆé‹å‹•çš„éŸ³æ¨‚",
        "Taylor Swift çš„æ­Œ",
        "é¡ä¼¼ Bohemian Rhapsody çš„æ­Œ",
        "æ¨è–¦åƒ Adele çš„æ­Œæ‰‹",
        "çµ¦æˆ‘æ—¥æœ¬æµè¡Œæ­Œ",
        "æ›´å¤šé€™ç¨®é¢¨æ ¼çš„ jazz"
    ]
    
    print("=" * 80)
    print("ğŸ¯ è·¯ç”±å™¨æ¸¬è©¦")
    print("=" * 80)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n[æ¸¬è©¦ {i}] æŸ¥è©¢: ã€Œ{query}ã€")
        print("-" * 80)
        
        decision = router.route_query(query)
        
        print(f"âœ“ é¡å‹: {decision.query_type.value}")
        print(f"âœ“ Clustering: {'æ˜¯' if decision.use_clustering else 'å¦'}")
        print(f"âœ“ ä¿¡å¿ƒ: {decision.confidence:.2f}")
        print(f"âœ“ ç†ç”±: {decision.reasoning}")
        print(f"âœ“ æå–è³‡è¨Š: {json.dumps(decision.extracted_info, ensure_ascii=False, indent=2)}")